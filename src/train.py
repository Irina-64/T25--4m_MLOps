import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
import joblib
import mlflow
import mlflow.sklearn
from datetime import datetime
import os

def train_model():
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow
    mlflow.set_tracking_uri("sqlite:///mlflow.db")
    mlflow.set_experiment("telco_churn")
    
    # –í–∫–ª—é—á–∞–µ–º autolog –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    mlflow.sklearn.autolog()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    df = pd.read_csv('data/processed/processed.csv')
    print(f"üìä –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape}")
    print(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {df.columns.tolist()[:10]}...")  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    if 'customerID' in df.columns:
        X = df.drop(columns=['Churn', 'customerID'])
    else:
        X = df.drop(columns=['Churn'])
    
    y = df['Churn']
    
    print(f"üéØ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}, –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {y.shape[0]}")
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"üìà Train: {X_train.shape}, Test: {X_test.shape}")
    print(f"‚öñÔ∏è –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ –≤ train: {pd.Series(y_train).value_counts().to_dict()}")
    
    # –ú–æ–¥–µ–ª–∏
    models = {
        "RandomForest": RandomForestClassifier(n_estimators=100, random_state=42),
        "LogisticRegression": LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')
    }
    
    best_score = 0
    best_model = None
    best_model_name = ""
    best_run_id = ""
    
    for name, model in models.items():
        with mlflow.start_run(run_name=f"{name}_{datetime.now().strftime('%H%M%S')}") as run:
            print(f"\nü§ñ –û–±—É—á–µ–Ω–∏–µ {name}...")
            
            # –û–±—É—á–µ–Ω–∏–µ
            model.fit(X_train, y_train)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1]
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            accuracy = accuracy_score(y_test, y_pred)
            roc_auc = roc_auc_score(y_test, y_pred_proba)
            
            print(f"‚úÖ Accuracy: {accuracy:.4f}")
            print(f"‚úÖ ROC-AUC: {roc_auc:.4f}")
            
            # –í—Ä—É—á–Ω—É—é –ª–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            mlflow.log_param("model", name)
            mlflow.log_param("features_count", X_train.shape[1])
            mlflow.log_metric("accuracy", accuracy)
            mlflow.log_metric("roc_auc", roc_auc)
            mlflow.log_metric("test_size", X_test.shape[0])
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            from sklearn.metrics import precision_score, recall_score, f1_score
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            
            mlflow.log_metric("precision", precision)
            mlflow.log_metric("recall", recall)
            mlflow.log_metric("f1_score", f1)
            
            # –í—Ä—É—á–Ω—É—é –ª–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º artifact_path
            mlflow.sklearn.log_model(
                sk_model=model,
                artifact_path="model",  # –í–∞–∂–Ω–æ: –∏–º–µ–Ω–Ω–æ "model" –∞ –Ω–µ —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ
                registered_model_name="telco_churn_model"
            )
            
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞ –≤ MLflow (run_id: {run.info.run_id})")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            if roc_auc > best_score:
                best_score = roc_auc
                best_model = model
                best_model_name = name
                best_run_id = run.info.run_id
    
    # –û—Ç–∫–ª—é—á–∞–µ–º autolog —á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞–ª –¥—Ä—É–≥–∏–º —Å–∫—Ä–∏–ø—Ç–∞–º
    mlflow.sklearn.autolog(disable=True)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤ —Ñ–∞–π–ª
    if best_model is not None:
        os.makedirs("models", exist_ok=True)
        model_filename = f"models/{best_model_name.lower()}_model.joblib"
        joblib.dump(best_model, model_filename)
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ model.joblib –¥–ª—è API
        joblib.dump(best_model, "models/model.joblib")
        
        print(f"\nüéâ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
        print(f"üìä ROC-AUC: {best_score:.4f}")
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫: {model_filename}")
        print(f"üíæ –ò –∫–∞–∫: models/model.joblib (–¥–ª—è API)")
        print(f"üîó Run ID: {best_run_id}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º run_id –≤ —Ñ–∞–π–ª –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
        with open("models/best_run_id.txt", "w") as f:
            f.write(best_run_id)
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        with open("models/best_model_info.json", "w") as f:
            import json
            json.dump({
                "model_name": best_model_name,
                "roc_auc": best_score,
                "run_id": best_run_id,
                "timestamp": datetime.now().isoformat()
            }, f)
    
    print(f"\nüìä MLflow tracking URI: {mlflow.get_tracking_uri()}")
    print("üìÅ –î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: mlflow ui --backend-store-uri sqlite:///mlflow.db")
    
    return best_model, best_score, best_run_id

if __name__ == "__main__":
    model, score, run_id = train_model()