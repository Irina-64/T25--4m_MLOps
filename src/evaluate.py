import json
import joblib
import pandas as pd
from sklearn.metrics import roc_auc_score, confusion_matrix, precision_score, recall_score
import os

# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º –∏ –º–æ–¥–µ–ª—è–º
TEST_PATH = "/workspace/data/processed/test_data.csv"
MODEL_PATH = "/workspace/models/lgb_model.joblib"
REPORT_PATH = "/workspace/reports/eval.json"

'''
def main():
    # –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –Ω—É–∂–Ω—ã–µ —Ñ–∞–π–ª—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    if not os.path.exists(TEST_PATH):
        raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {TEST_PATH}")
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å: {MODEL_PATH}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    data = pd.read_csv(TEST_PATH)
    if "churn" not in data.columns:
        raise ValueError("–í —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ –Ω–µ—Ç —Å—Ç–æ–ª–±—Ü–∞ 'churn' (—Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è).")

    X_test = data.drop(columns=["churn", "user_id"], errors="ignore")
    y_test = data["churn"]

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = joblib.load(MODEL_PATH)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    # –ú–µ—Ç—Ä–∏–∫–∏
    metrics = {
        "roc_auc": float(roc_auc_score(y_test, y_proba)) if y_proba is not None else None,
        "precision": float(precision_score(y_test, y_pred)),
        "recall": float(recall_score(y_test, y_pred)),
        "confusion_matrix": confusion_matrix(y_test, y_pred).tolist()
    }

    # –°–æ–∑–¥–∞–¥–∏–º –ø–∞–ø–∫—É –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    os.makedirs(os.path.dirname(REPORT_PATH), exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON
    with open(REPORT_PATH, "w") as f:
        json.dump(metrics, f, indent=4, ensure_ascii=False)

    print(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {REPORT_PATH}")
    print(json.dumps(metrics, indent=4, ensure_ascii=False))


if __name__ == "__main__":
    main()'''

def main():
    # === 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–µ–π ===
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {MODEL_PATH}")
    if not os.path.exists(TEST_PATH):
        raise FileNotFoundError(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {TEST_PATH}")

    # === 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –¥–∞–Ω–Ω—ã—Ö ===
    model = joblib.load(MODEL_PATH)
    df = pd.read_csv(TEST_PATH)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {df.shape}")

    # === 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª—å ===
    X_test = df.drop(columns=["user_id", "churn"])
    y_test = df["churn"]

    # === 4. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫ –æ–±—É—á–∞—é—â–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º ===
    train_feature_count = model.n_features_in_
    print(f"üîç –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ {train_feature_count} –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö, —Ç–µ—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç {X_test.shape[1]}.")

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
    if X_test.shape[1] != train_feature_count:
        print("‚öôÔ∏è –ü—Ä–∏–≤–æ–¥–∏–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∫ –Ω—É–∂–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º...")
        model_features = model.feature_name_ if hasattr(model, "feature_name_") else None
        if model_features:
            missing_cols = [f for f in model_features if f not in X_test.columns]
            extra_cols = [f for f in X_test.columns if f not in model_features]

            if missing_cols:
                print(f"‚ö†Ô∏è –í —Ç–µ—Å—Ç–µ –Ω–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {missing_cols}")
                for col in missing_cols:
                    X_test[col] = 0  # –¥–æ–±–∞–≤–∏–º –ø—É—Å—Ç—ã–µ –∫–æ–ª–æ–Ω–∫–∏

            if extra_cols:
                print(f"‚ö†Ô∏è –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {extra_cols}")
                X_test = X_test[model_features]
        else:
            raise ValueError("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö.")

    # === 5. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ===
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    # === 6. –ú–µ—Ç—Ä–∏–∫–∏ ===
    roc_auc = roc_auc_score(y_test, y_proba)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    conf_mat = confusion_matrix(y_test, y_pred).tolist()

    results = {
        "roc_auc": roc_auc,
        "precision": precision,
        "recall": recall,
        "confusion_matrix": conf_mat,
    }

    # === 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ===
    os.makedirs(os.path.dirname(REPORT_PATH), exist_ok=True)
    with open(REPORT_PATH, "w") as f:
        json.dump(results, f, indent=4)

    print("‚úÖ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤:", REPORT_PATH)
    print(json.dumps(results, indent=4))


if __name__ == "__main__":
    main()

