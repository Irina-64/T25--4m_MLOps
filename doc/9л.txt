❓ Почему step_id — Entity?

Ответ:

Потому что признаки описывают состояние среды в конкретный момент времени, и шаг игры является естественным идентификатором такого состояния.

❓ Почему не весь state?

Ответ:

В Feature Store вынесены агрегированные и устойчивые признаки, а детальное представление состояния остаётся внутри RL-агента.

Лабораторная работа 9 — Feature Store (Feast) — оффлайн материализация и использование в обучении
============================================================================================

Проект: RL-агент для карточной игры "Дурак"
--------------------------------------------------

Цель работы:
------------
Вынести признаки состояния игры в feature store и интегрировать их с этапом тренировки/предсказаний агента, без изменения ключевой архитектуры RL-агента.

Инструменты и технологии:
-------------------------
- Python 3.12 (виртуальное окружение venv)
- PyTorch
- pandas, numpy
- Локальный аналог feature store: SimpleFeatureStore (CSV)
- Проект RL-агента для игры "Дурак"

---

Шаг 1: Инициализация feature store
-----------------------------------
- Создан каталог `feature_repo/`.
- Создан файл `feature_store.yaml` (не использовался в дальнейшем, так как возникли проблемы с установкой Feast на Python 3.12).
- Использован собственный локальный класс `SimpleFeatureStore`, который сохраняет фичи в CSV (`rl_state_features.csv`).
- Файл `features.py` и `example.py` созданы для структуры проекта, feature logging реализован в `feature_logging.py`.

---

Шаг 2: Определение entity и feature view
----------------------------------------
- Entity: `pid` — идентификатор игрока.
- Feature view: набор признаков состояния игры RL-агента:
  - Scalar features: козырь, размер колоды, размер сброса, кто атакует/защищается, статус игры, размеры рук других игроков.
  - Кодировка стола: `encode_table`.
  - Кодировка руки игрока: `encode_hand`.
- Фичи нормализованы и объединены в один тензор длиной 636.

---

Шаг 3: Подготовка оффлайн таблицы и materialize
------------------------------------------------
- Функция `log_state_features` в тесте RLAgent записывает состояния во время матчей в CSV.
- Проведены тестовые матчи с ботом (100 эпизодов).
- Создан CSV `rl_state_features.csv` с 1985 записями.
- Каждая запись содержит:
  - state_id (`эпизод_шаг`)
  - вектор признаков длиной 636.

---

Шаг 4: Интеграция feature store с тренировкой
---------------------------------------------
- RLAgent не изменялся; `state_to_tensor` остался ключевым элементом.
- На каждом шаге RLAgent добавлена запись состояния в feature store через `log_state_features`.
- Данные из CSV могут использоваться для оффлайн обучения или анализа без изменения структуры агента.

---

Шаг 5: Проверка использования оффлайн feature store
---------------------------------------------------
- Пример доступа к оффлайн фичам:
```python
import pandas as pd
df = pd.read_csv("rl_state_features.csv")
first_features = df[df["Unnamed: 0"]=="1_0"]["features"].iloc[0]
print(first_features)

Длина векторов фич: 636, значения scalar features нормализованы, padding заполнен нулями.
Результаты:

Feature store создан и интегрирован в тренировку RL-агента.

Все новые данные логируются в CSV.

RLAgent может обучаться и тестироваться с использованием этих фич.

Структура кода RL-агента и state_to_tensor не изменялась, только расширялся pipeline логирования.

Вывод:

Лабораторная работа выполнена в рамках текущего проекта RL-агента.

Используется локальный CSV как оффлайн feature store.

Цель — демонстрация концепции feature store и возможности интеграции в обучение — достигнута.