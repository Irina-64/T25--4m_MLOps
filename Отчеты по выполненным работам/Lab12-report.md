# Лабораторная работа №12

## Детекция дрейфа данных и автоматический retraining

### Цель работы

Реализовать систему обнаружения дрейфа данных (feature drift / performance drift) и автоматическую реакцию в виде перезапуска обучения модели. Построить процесс, включающий:

* регулярную проверку распределений признаков (PSI/KS),
* контроль деградации качества модели (performance drift),
* генерацию отчёта о дрейфе,
* автоматический запуск retrain DAG в Airflow при превышении порога.

---

## 1. Реализация скрипта детекции дрейфа (`src/drift_check.py`)

Был создан модуль `src/drift_check.py`, включающий:

### 1.1 Feature Drift

Для сравнения обучающей выборки и продакшен-запросов вычисляются:

* **PSI (Population Stability Index)** — оценка изменения распределений признаков.

  * PSI > 0.2: дрейф считается значительным.
* **KS-тест** — оценка статистического различия между выборками.

Признаки формируются из исходного текста:

* длина входного текста,
* количество слов,
* длина таргета,
* количество слов в таргете.

```python
features = pd.DataFrame({
    "input_length": df["input_text"].apply(len),
    "input_word_count": df["input_text"].apply(lambda x: len(x.split())),
    "target_length": df["target_text"].apply(len),
    "target_word_count": df["target_text"].apply(lambda x: len(x.split())),
})
```

### 1.2 Performance Drift

Для оценки деградации модели используем:

* BLEU-score на контрольном наборе,
* сравнение BLEU модели на train/validation и на последних продакшен-запросах.

Если BLEU снизился больше чем на заданный порог — фиксируется performance drift.

### 1.3 Генерация отчёта

Результат проверки сохраняется в файл:

```
reports/drift_report.json
```

с содержимым вида:

```json
{
  "timestamp": "...",
  "psi_scores": {...},
  "ks_results": {...},
  "performance_drift": {...},
  "drift_detected": true
}
```

Этот отчёт затем используется Airflow для принятия решения.

---

## 2. Airflow DAG для автоматического запуска retraining

Был разработан DAG `drift_monitoring`, который решает следующие задачи:

1. **Периодически запускает drift_check.py**

   * расписание: каждые 6 часов.

2. **Читает отчёт дрейфа (`drift_report.json`)**

3. **Ветвление:**

   * если `drift_detected = false` → выполнение уходит на ветку `no_drift`,
   * если `true` → активируется ветка retraining.

4. **Триггер retraining**
   Через `TriggerDagRunOperator` инициируется запуск DAG `flight_pipeline` (или другого DAG, ответственного за переобучение модели).

Фрагмент кода:

```python
if report.get("drift_detected", False):
    return "trigger_retrain"
return "no_drift"
```

Две ветки DAG:

* `no_drift` — логирует стабильность данных,
* `trigger_retrain` — запускает обучение (например, `train.py` или retrain DAG).

Таким образом, Airflow функционирует как «сторож» изменений данных.

---

## 3. Смоделированный дрейф и демонстрация работы системы

### 3.1 Имитация дрейфа

Чтобы продемонстрировать корректность системы, было выполнено:

* изменение продакшен-выборки (`production_data.csv`),
* искусственное смещение распределений признаков,
* изменение текста для ухудшения BLEU.

В результате:

* PSI по некоторым признакам вырос до значений `> 0.2`,
* performance drift стал положительным (`BLEU_diff > 0.03`),
* `drift_report.json` содержал `drift_detected = true`.

### 3.2 Срабатывание DAG

При следующем запуске Airflow DAG:

* задача `drift_check` выполняется,
* ветвление `decide_drift` выбирает путь `trigger_retrain`,
* Airflow автоматически запускает DAG переобучения.

Тем самым система полностью удовлетворяет требованию «автоматической реакции на дрейф».

---

## 4. Артефакты лабораторной работы

В результате выполнения были получены следующие артефакты:

* `src/drift_check.py` — скрипт проверки дрейфа, формирующий отчёт.
* `reports/drift_report.json` — отчёт о текущем состоянии данных.
* `airflow/dags/drift_monitoring.py` — DAG проверки дрейфа.
* Автоматический запуск retraining при обнаружении drift.
* Скриншоты работы DAG (ветки `no_drift` и `trigger_retrain`).

---

## Вывод

В ходе лабораторной работы была создана полноценная система мониторинга дрейфа данных и качества модели:

* реализована детекция feature и performance drift,
* настроен регулярный запуск проверки,
* добавлен автоматический триггер retraining,
* успешно смоделирован дрейф и показано, что система корректно реагирует на него.

Все цели лабораторной работы выполнены.

```}
```

## Распределение задач в команде

**Власюк Данил** — настроил конфигурацию Feast (`feature_store.yaml`), описал offline и online store, организовал структуру проекта.

**Скрыпник Михаил** — подготовил оффлайн-таблицу признаков `data/features/detox_features.csv` на основе обработанных train/test данных, добавил идентификаторы и временные метки.

**Беспалый Максим** — интегрировал Feast в `src/train.py`, заменив локальное чтение CSV на `FeatureStore.get_historical_features`, проверил сборку обучающих датасетов и корректность вычисления метрик.

**Провков Иван** — выполнил `feast apply` и `feast materialize`, проверил возврат признаков из оффлайн стора, убедился в корректности артефактов в `feature_repo/data`.

**Яковенко Максим** — подготовил отчёт по лабораторной работе, структурировал шаги запуска и собрал итоговые артефакты.
